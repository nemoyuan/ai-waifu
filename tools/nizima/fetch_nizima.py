#!/usr/bin/env python3
"""
Nizima Live2Dæ¨¡å‹ä¸‹è½½å™¨ v3.0
æ”¯æŒåŒæ—¶ä¸‹è½½previewå’Œexportç‰ˆæœ¬
"""

import asyncio
import json
import os
import shutil
import signal
import tempfile
import time
import zipfile
from contextlib import asynccontextmanager
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import aiohttp


# ==================== æ•°æ®ç»“æ„ ====================
# ExportåŠŸèƒ½éœ€è¦ç”¨æˆ·ç™»å½•è®¤è¯ï¼Œç›®å‰ä»…æ”¯æŒpreviewä¸‹è½½
ENABLE_EXPORT_ATTEMPT = False

# è„šæœ¬ç‰ˆæœ¬æ§åˆ¶
SCRIPT_VERSION = "v4"

# å…¨å±€ä¸­æ–­æ ‡å¿—
_shutdown_requested = False


def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼šä¼˜é›…å¤„ç†ä¸­æ–­"""
    global _shutdown_requested
    _shutdown_requested = True
    print("\nğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
    print("â³ ç­‰å¾…å½“å‰æ“ä½œå®Œæˆï¼Œè¯·ç¨å€™...")


def is_shutdown_requested() -> bool:
    """æ£€æŸ¥æ˜¯å¦è¯·æ±‚å…³é—­"""
    return _shutdown_requested


# ==================== å·¥å…·å‡½æ•° ====================


def check_version(item_id: str, output_dir: str) -> bool:
    """æ£€æŸ¥ä½œå“ç‰ˆæœ¬æ˜¯å¦ä¸ºæœ€æ–°"""

    def _check_version_file(version_file: Path, dir_name: str = None) -> bool:
        """æ£€æŸ¥å•ä¸ªç‰ˆæœ¬æ–‡ä»¶"""
        try:
            with open(version_file, "r", encoding="utf-8") as f:
                version_data = json.load(f)
            current_version = version_data.get("version")

            if current_version == SCRIPT_VERSION:
                print(f"âœ… ä½œå“ {item_id} å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ ({SCRIPT_VERSION})ï¼Œè·³è¿‡ä¸‹è½½")
                if dir_name:
                    print(f"ğŸ“ æ‰¾åˆ°ç›®å½•: {dir_name}")
                return True
            else:
                print(
                    f"ğŸ”„ ä½œå“ {item_id} ç‰ˆæœ¬ä¸åŒ¹é… (æœ¬åœ°: {current_version}, å½“å‰: {SCRIPT_VERSION})ï¼Œéœ€è¦æ›´æ–°"
                )
                if dir_name:
                    print(f"ğŸ“ æ‰¾åˆ°ç›®å½•: {dir_name}")
                return False
        except Exception:
            return False

    try:
        output_path = Path(output_dir)

        # é¦–å…ˆæŸ¥æ‰¾åŸå§‹æ ¼å¼çš„ç›®å½• {item_id}/
        version_file = output_path / item_id / "version.json"
        if version_file.exists():
            return _check_version_file(version_file)

        # å¦‚æœåŸå§‹æ ¼å¼ä¸å­˜åœ¨ï¼ŒæŸ¥æ‰¾é‡å‘½åæ ¼å¼çš„ç›®å½• {item_id}_*/
        for dir_path in output_path.iterdir():
            if dir_path.is_dir() and dir_path.name.startswith(f"{item_id}_"):
                version_file = dir_path / "version.json"
                if version_file.exists():
                    return _check_version_file(version_file, dir_path.name)

        # éƒ½æ²¡æ‰¾åˆ°
        return False

    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ç‰ˆæœ¬å¤±è´¥: {e}")
        return False


def save_version(item_id: str, output_dir: str):
    """ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯åˆ°version.json"""
    try:
        version_file = Path(output_dir) / item_id / "version.json"
        version_file.parent.mkdir(parents=True, exist_ok=True)

        version_data = {
            "version": SCRIPT_VERSION,
            "updated_at": datetime.now().isoformat(),
            "item_id": item_id,
        }

        with open(version_file, "w", encoding="utf-8") as f:
            json.dump(version_data, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ ç‰ˆæœ¬ä¿¡æ¯å·²ä¿å­˜: {version_file} ({SCRIPT_VERSION})")

    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")


# ==================== æ•°æ®ç»“æ„ ====================


class TaskType(Enum):
    PREVIEW_FILE = "preview_file"
    EXPORT_FILE = "export_file"
    THUMBNAIL = "thumbnail"
    PREVIEW_IMAGE = "preview_image"


@dataclass
class DownloadTask:
    task_type: TaskType
    url: str
    target_path: Path
    temp_path: Path
    needs_processing: bool = False
    file_name: Optional[str] = None  # ç”¨äºexportä¸‹è½½çš„fileNameå‚æ•°


@dataclass
class ProcessingResult:
    success: bool
    task: DownloadTask
    final_path: Optional[Path] = None
    error: Optional[str] = None
    model_name: Optional[str] = None  # æ–°å¢ï¼šæ¨¡å‹åç§°


@dataclass
class AssetsInfo:
    """èµ„æºä¿¡æ¯"""

    item_id: str
    preview_live2d_zip: Optional[Dict[str, str]] = None
    export_zip_info: Optional[Dict[str, Any]] = None  # åŒ…å«itemContentIdç­‰ä¿¡æ¯
    thumbnail_image: Optional[Dict[str, str]] = None
    preview_images: List[Dict[str, str]] = None

    @classmethod
    def from_api_response(cls, data: Dict[str, Any]) -> "AssetsInfo":
        """ä»APIå“åº”åˆ›å»ºAssetsInfo"""
        assets_info = data.get("assetsInfo", {})
        item_content_details = data.get("itemContentDetails", {})

        # æå–exportä¿¡æ¯
        export_zip_info = None
        export_data_key = "æ›¸ãå‡ºã—ãƒ‡ãƒ¼ã‚¿"
        if export_data_key in item_content_details:
            export_info = item_content_details[export_data_key]
            if ENABLE_EXPORT_ATTEMPT or export_info.get("isDownloadable", False):
                export_zip_info = {
                    "itemContentId": export_info["itemContentId"],
                    "fileSize": export_info.get("fileSize", "Unknown"),
                    "isDownloadable": True,
                }

        return cls(
            item_id=str(data.get("itemId", "")),
            preview_live2d_zip=assets_info.get("previewLive2DZip"),
            export_zip_info=export_zip_info,
            thumbnail_image=assets_info.get("thumbnailImage"),
            preview_images=assets_info.get("previewImages", []),
        )


# ==================== å®‰å…¨æ–‡ä»¶ç®¡ç†å™¨ ====================


class SafeFileManager:
    """å®‰å…¨æ–‡ä»¶æ“ä½œç®¡ç†å™¨"""

    def __init__(self, target_dir: Path):
        self.target_dir = target_dir
        self.backup_dir = target_dir.with_name(f"{target_dir.name}_back")
        self.temp_dir = Path("models/nizima/.temp") / target_dir.name
        self.rename_callback = None  # é‡å‘½åå›è°ƒå‡½æ•°

    def set_rename_callback(self, callback):
        """è®¾ç½®é‡å‘½åå›è°ƒå‡½æ•°"""
        self.rename_callback = callback

    @asynccontextmanager
    async def safe_operation(self):
        """å®‰å…¨æ“ä½œä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            # 1. å¤‡ä»½ç°æœ‰ç›®å½•
            if self.target_dir.exists():
                if self.backup_dir.exists():
                    shutil.rmtree(self.backup_dir)
                shutil.move(str(self.target_dir), str(self.backup_dir))
                print(f"ğŸ“¦ å·²å¤‡ä»½ç°æœ‰ç›®å½•: {self.target_dir} -> {self.backup_dir}")

            # 2. åˆ›å»ºä¸´æ—¶ç›®å½•
            self.temp_dir.mkdir(parents=True, exist_ok=True)

            # 3. æä¾›ä¸Šä¸‹æ–‡
            ctx = type(
                "Context",
                (),
                {"temp_dir": self.temp_dir, "target_dir": self.target_dir},
            )()

            yield ctx

            # 4. æˆåŠŸæ—¶ç§»åŠ¨åˆ°æœ€ç»ˆä½ç½®
            if self.temp_dir.exists():
                self.target_dir.parent.mkdir(parents=True, exist_ok=True)

                # ç§»åŠ¨temp_dirçš„å†…å®¹åˆ°target_dirï¼Œè€Œä¸æ˜¯ç§»åŠ¨temp_diræœ¬èº«
                if self.target_dir.exists():
                    shutil.rmtree(self.target_dir)

                # é‡å‘½åtemp_dirä¸ºtarget_dir
                self.temp_dir.rename(self.target_dir)
                print(f"âœ… å·²ç§»åŠ¨åˆ°æœ€ç»ˆä½ç½®: {self.temp_dir} -> {self.target_dir}")

                # å¦‚æœæœ‰é‡å‘½åå›è°ƒï¼Œæ‰§è¡Œé‡å‘½å
                if self.rename_callback:
                    new_target_dir = self.rename_callback()
                    if new_target_dir != self.target_dir:
                        self.target_dir = new_target_dir

            # 5. åˆ é™¤å¤‡ä»½
            if self.backup_dir.exists():
                shutil.rmtree(self.backup_dir)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤å¤‡ä»½: {self.backup_dir}")

        except Exception as e:
            print(f"âŒ æ“ä½œå¤±è´¥ï¼Œå¼€å§‹å›æ»š: {e}")

            # å›æ»šæ“ä½œ
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
                print(f"ğŸ§¹ å·²æ¸…ç†ä¸´æ—¶ç›®å½•: {self.temp_dir}")

            if self.backup_dir.exists():
                if self.target_dir.exists():
                    shutil.rmtree(self.target_dir)
                shutil.move(str(self.backup_dir), str(self.target_dir))
                print(f"ğŸ”„ å·²æ¢å¤å¤‡ä»½: {self.backup_dir} -> {self.target_dir}")

            raise


# ==================== ä¸‹è½½ç®¡ç†å™¨ ====================


class DownloadManager:
    """å¹¶å‘ä¸‹è½½ç®¡ç†å™¨"""

    def __init__(self, max_concurrent: int = 5, max_retries: int = 3):
        self.max_concurrent = max_concurrent
        self.max_retries = max_retries
        self.session: Optional[aiohttp.ClientSession] = None
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.failed_downloads: List[Dict[str, str]] = []

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=300),
            connector=aiohttp.TCPConnector(limit=20),
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def download_tasks(self, tasks: List[DownloadTask]) -> List[ProcessingResult]:
        """å¹¶å‘ä¸‹è½½ä»»åŠ¡åˆ—è¡¨"""
        print(f"ğŸš€ å¼€å§‹å¹¶å‘ä¸‹è½½ {len(tasks)} ä¸ªä»»åŠ¡")

        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘
        async def download_with_semaphore(task):
            async with self.semaphore:
                return await self._download_file(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        results = await asyncio.gather(
            *[download_with_semaphore(task) for task in tasks], return_exceptions=True
        )

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(
                    ProcessingResult(success=False, task=tasks[i], error=str(result))
                )
            else:
                processed_results.append(result)

        success_count = sum(1 for r in processed_results if r.success)
        print(f"ğŸ“Š ä¸‹è½½å®Œæˆ: {success_count}/{len(tasks)} æˆåŠŸ")

        return processed_results

    async def _download_file(self, task: DownloadTask) -> ProcessingResult:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•"""
        # æ£€æŸ¥æ˜¯å¦è¯·æ±‚å…³é—­
        if is_shutdown_requested():
            return ProcessingResult(success=False, task=task, error="ç”¨æˆ·è¯·æ±‚ä¸­æ–­ä¸‹è½½")

        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        task.temp_path.parent.mkdir(parents=True, exist_ok=True)

        print(f"â¬‡ï¸ ä¸‹è½½ {task.task_type.value}: {task.url}")

        last_error = None

        for attempt in range(self.max_retries + 1):
            try:
                if task.task_type == TaskType.EXPORT_FILE:
                    # exportæ–‡ä»¶éœ€è¦ç‰¹æ®Šçš„POSTè¯·æ±‚
                    form_data = aiohttp.FormData()
                    form_data.add_field("fileName", task.file_name or "export.zip")

                    async with self.session.post(task.url, data=form_data) as response:
                        # æ£€æŸ¥æ˜¯å¦è¿”å›äº†ç™»å½•é¡µé¢
                        content_type = response.headers.get("content-type", "")
                        if "text/html" in content_type:
                            raise Exception(
                                "Exportä¸‹è½½éœ€è¦ç”¨æˆ·ç™»å½•è®¤è¯ã€‚è¯·åœ¨æµè§ˆå™¨ä¸­ç™»å½•Nizimaè´¦æˆ·åå†å°è¯•ï¼Œæˆ–è€…ä»…ä½¿ç”¨Previewæ¨¡å¼ã€‚"
                            )

                        response.raise_for_status()
                        result = await response.json()

                        if not result.get("isSucceeded") or not result.get(
                            "downloadUrl"
                        ):
                            raise Exception(f"ä¸‹è½½APIè¿”å›å¤±è´¥: {result}")

                        # ä½¿ç”¨è¿”å›çš„downloadUrlä¸‹è½½æ–‡ä»¶
                        async with self.session.get(
                            result["downloadUrl"]
                        ) as file_response:
                            file_response.raise_for_status()
                            content = await file_response.read()
                else:
                    # æ™®é€šGETè¯·æ±‚
                    async with self.session.get(task.url) as response:
                        response.raise_for_status()
                        content = await response.read()

                # å†™å…¥ä¸´æ—¶æ–‡ä»¶
                with open(task.temp_path, "wb") as f:
                    f.write(content)

                print(f"âœ… ä¸‹è½½å®Œæˆ: {task.temp_path.name} ({len(content):,} bytes)")

                return ProcessingResult(
                    success=True, task=task, final_path=task.temp_path
                )

            except Exception as e:
                last_error = e

                if attempt < self.max_retries:
                    # æŒ‡æ•°é€€é¿ï¼š3ç§’ã€6ç§’ã€12ç§’
                    delay = 3 * (2**attempt)
                    print(
                        f"âš ï¸ ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries + 1}): {e}"
                    )
                    print(f"ğŸ”„ {delay}ç§’åé‡è¯•...")
                    await asyncio.sleep(delay)
                else:
                    # æœ€ç»ˆå¤±è´¥ï¼Œè®°å½•åˆ°å¤±è´¥åˆ—è¡¨
                    print(f"âŒ ä¸‹è½½æœ€ç»ˆå¤±è´¥ {task.url}: {e}")
                    self.failed_downloads.append(
                        {
                            "url": task.url,
                            "target_path": str(task.target_path),
                            "task_type": task.task_type.value,
                            "error": str(e),
                        }
                    )

        return ProcessingResult(success=False, task=task, error=str(last_error))

    def write_failure_log(self, output_dir: Path, item_id: str = None):
        """å°†å¤±è´¥çš„ä¸‹è½½è®°å½•å†™å…¥æ—¥å¿—æ–‡ä»¶"""
        if not self.failed_downloads:
            return

        log_file = output_dir / "fail_list.txt"

        # è¯»å–ç°æœ‰å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        existing_content = ""
        if log_file.exists():
            with open(log_file, "r", encoding="utf-8") as f:
                existing_content = f.read()

        # å‡†å¤‡æ–°å†…å®¹
        new_entries = []
        for failure in self.failed_downloads:
            entry = f"""
å¤±è´¥è®°å½• - {time.strftime('%Y-%m-%d %H:%M:%S')}
ä½œå“ID: {item_id or 'Unknown'}
ä»»åŠ¡ç±»å‹: {failure['task_type']}
å¤±è´¥URL: {failure['url']}
ç›®æ ‡è·¯å¾„: {failure['target_path']}
é”™è¯¯ä¿¡æ¯: {failure['error']}
{'='*60}"""
            new_entries.append(entry)

        # å†™å…¥æ–‡ä»¶
        with open(log_file, "w", encoding="utf-8") as f:
            if existing_content:
                f.write(existing_content)
            f.write("\n".join(new_entries))

        print(f"ğŸ“ å¤±è´¥è®°å½•å·²å†™å…¥: {log_file}")
        print(f"ğŸ“Š æœ¬æ¬¡å¤±è´¥æ•°é‡: {len(self.failed_downloads)}")

        # æ¸…ç©ºå¤±è´¥åˆ—è¡¨
        self.failed_downloads.clear()


# ==================== æ–‡ä»¶å¤„ç†å™¨ ====================


class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""

    XOR_KEY = "AkqeZ-f,7fgx*7WU$6mWZ_98x-nWtdw4Jjky"
    ZIP_PASSWORD = "LrND6UfK(j-NmN7tTb+2S&6J56rEdfHJ3+pA"

    @classmethod
    async def process_main_file(
        cls, file_path: Path, target_dir: Path, file_type: str
    ) -> bool:
        """å¤„ç†ä¸»æ–‡ä»¶ï¼ˆpreviewæˆ–exportï¼‰"""
        try:
            print(f"ğŸ”§ å¤„ç†{file_type}æ–‡ä»¶...")

            # åˆ›å»ºå¯¹åº”çš„å­ç›®å½•
            type_dir = target_dir / file_type
            type_dir.mkdir(parents=True, exist_ok=True)

            # æ£€æµ‹æ–‡ä»¶ç±»å‹
            if cls._is_zip_file(file_path):
                print(f"âœ… æ–‡ä»¶å·²æ˜¯ZIPæ ¼å¼")
                zip_path = file_path
            else:
                print(f"ğŸ”“ æ–‡ä»¶éœ€è¦è§£å¯†")
                zip_path = await cls._decrypt_file(file_path)
                if not zip_path:
                    return False

            # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
            temp_extract_dir = target_dir / f".temp_{file_type}_extract"
            temp_extract_dir.mkdir(parents=True, exist_ok=True)

            success = await cls._extract_zip(zip_path, temp_extract_dir)
            if success:
                # ç§»åŠ¨ç›®å½•åˆ°ç›®æ ‡ä½ç½®ï¼Œè·å–æ¨¡å‹åç§°
                model_name = await cls._move_to_final_dir(
                    temp_extract_dir, type_dir, file_type
                )
                return model_name

            return False

        except Exception as e:
            print(f"âŒ å¤„ç†{file_type}æ–‡ä»¶å¤±è´¥: {e}")
            return False

    @classmethod
    def _is_zip_file(cls, file_path: Path) -> bool:
        """æ£€æµ‹æ–‡ä»¶æ˜¯å¦ä¸ºZIPæ ¼å¼"""
        try:
            with open(file_path, "rb") as f:
                header = f.read(4)
                # ZIPæ–‡ä»¶çš„é­”æ•°
                return header in [b"PK\x03\x04", b"PK\x05\x06", b"PK\x07\x08"]
        except Exception:
            return False

    @classmethod
    async def _decrypt_file(cls, file_path: Path) -> Optional[Path]:
        """è§£å¯†æ–‡ä»¶"""
        try:
            with open(file_path, "rb") as f:
                encrypted_data = f.read()

            # XORè§£å¯†
            key_bytes = [ord(c) for c in cls.XOR_KEY]
            decrypted = bytearray()

            for i, byte in enumerate(encrypted_data):
                decrypted.append(byte ^ key_bytes[i % len(key_bytes)])

            # ä¿å­˜è§£å¯†åçš„æ–‡ä»¶
            decrypted_path = file_path.with_suffix(".zip")
            with open(decrypted_path, "wb") as f:
                f.write(decrypted)

            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ZIPæ–‡ä»¶
            if cls._is_zip_file(decrypted_path):
                print("âœ… è§£å¯†æˆåŠŸï¼Œç¡®è®¤ä¸ºZIPæ–‡ä»¶")
                return decrypted_path
            else:
                print("âŒ è§£å¯†åä¸æ˜¯æœ‰æ•ˆçš„ZIPæ–‡ä»¶")
                return None

        except Exception as e:
            print(f"âŒ è§£å¯†å¤±è´¥: {e}")
            return None

    @classmethod
    async def _extract_zip(cls, zip_path: Path, extract_dir: Path) -> bool:
        """è§£å‹ZIPæ–‡ä»¶"""
        try:
            print(f"ğŸ“¦ æ­£åœ¨è§£å‹ZIPæ–‡ä»¶åˆ°: {extract_dir}")

            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                file_count = len(zip_ref.namelist())
                print(f"ğŸ“Š ZIPæ–‡ä»¶åŒ…å« {file_count} ä¸ªæ–‡ä»¶")

                # å…ˆå°è¯•ä½¿ç”¨å¯†ç è§£å‹
                try:
                    zip_ref.extractall(extract_dir, pwd=cls.ZIP_PASSWORD.encode())
                    print("âœ… å¯†ç è§£å‹æˆåŠŸ")
                except Exception:
                    # å¦‚æœå¯†ç è§£å‹å¤±è´¥ï¼Œå°è¯•æ— å¯†ç è§£å‹
                    try:
                        zip_ref.extractall(extract_dir)
                        print("âœ… æ— å¯†ç è§£å‹æˆåŠŸ")
                    except Exception as e:
                        print(f"âŒ è§£å‹å¤±è´¥: {e}")
                        return False

            return True

        except Exception as e:
            print(f"âŒ è§£å‹å¤±è´¥: {e}")
            return False

    @classmethod
    async def _move_to_final_dir(
        cls, extract_dir: Path, target_dir: Path, file_type: str
    ) -> Optional[str]:
        """å°†è§£å‹çš„æ–‡ä»¶ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•ï¼Œè¿”å›æ¨¡å‹åç§°"""
        try:
            # æŸ¥æ‰¾.moc3æ–‡ä»¶ç¡®è®¤è¿™æ˜¯Live2Dæ¨¡å‹
            moc3_files = list(extract_dir.rglob("*.moc3"))
            if moc3_files:
                moc3_file = moc3_files[0]
                model_name = moc3_file.stem
                print(f"ğŸ­ æ‰¾åˆ°Live2Dæ¨¡å‹: {model_name}")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°.moc3æ–‡ä»¶")
                model_name = "unknown_model"

            # ç›´æ¥ä½¿ç”¨file_typeä½œä¸ºæœ€ç»ˆç›®å½•åï¼ˆå¦‚previewã€exportï¼‰
            final_dir = target_dir

            # ç¡®ä¿ç›®æ ‡ç›®å½•çš„çˆ¶ç›®å½•å­˜åœ¨
            final_dir.parent.mkdir(parents=True, exist_ok=True)

            # ç§»åŠ¨ç›®å½•å†…å®¹
            if final_dir.exists():
                shutil.rmtree(final_dir)

            # å¦‚æœextract_dirç›´æ¥åŒ…å«æ¨¡å‹æ–‡ä»¶ï¼Œç›´æ¥é‡å‘½å
            if any(extract_dir.glob("*.moc3")):
                extract_dir.rename(final_dir)
            else:
                # å¦‚æœæœ‰å­ç›®å½•ï¼Œç§»åŠ¨ç¬¬ä¸€ä¸ªå­ç›®å½•çš„å†…å®¹
                subdirs = [d for d in extract_dir.iterdir() if d.is_dir()]
                if subdirs:
                    subdirs[0].rename(final_dir)
                    # æ¸…ç†ç©ºçš„extract_dir
                    if extract_dir.exists():
                        shutil.rmtree(extract_dir)
                else:
                    extract_dir.rename(final_dir)

            print(f"ğŸ“ {file_type}æ¨¡å‹ç›®å½•: {final_dir}")
            return model_name

        except Exception as e:
            print(f"âŒ ç§»åŠ¨ç›®å½•å¤±è´¥: {e}")
            return None

    @classmethod
    async def process_image(cls, file_path: Path, target_dir: Path) -> bool:
        """å¤„ç†å›¾ç‰‡æ–‡ä»¶"""
        try:
            # ç›´æ¥å¤åˆ¶åˆ°ç›®æ ‡ç›®å½•
            target_path = target_dir / file_path.name
            target_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(file_path, target_path)
            return True
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")
            return False


# ==================== èµ„æºç®¡ç†å™¨ ====================


class AssetsManager:
    """èµ„æºä¿¡æ¯ç®¡ç†å™¨"""

    def __init__(self, item_id: str):
        self.item_id = item_id
        self.user_items_path = "https://storage.googleapis.com/market_view_useritems"

    async def get_assets_info(self) -> AssetsInfo:
        """è·å–èµ„æºä¿¡æ¯"""
        api_url = f"https://nizima.com/api/items/{self.item_id}/detail"

        async with aiohttp.ClientSession() as session:
            async with session.get(api_url) as response:
                response.raise_for_status()

                # æ£€æŸ¥å“åº”ç±»å‹
                content_type = response.headers.get("content-type", "")
                if "application/json" not in content_type:
                    raise ValueError(
                        f"æ— æ•ˆçš„ä½œå“ID '{self.item_id}': APIè¿”å›äº†éJSONå“åº” (content-type: {content_type})"
                    )

                data = await response.json()

                # æ£€æŸ¥æ˜¯å¦æœ‰assetsInfo
                if "assetsInfo" not in data:
                    raise ValueError(
                        f"æ— æ•ˆçš„ä½œå“ID '{self.item_id}': å“åº”ä¸­ç¼ºå°‘assetsInfoå­—æ®µ"
                    )

                print(f"ğŸ“‹ è·å–åˆ°èµ„æºä¿¡æ¯: {self.item_id}")

                # ä¿å­˜å®Œæ•´çš„APIå“åº”æ•°æ®
                self._save_detail_json(data)

                return AssetsInfo.from_api_response(data), data

    def _save_detail_json(self, data: Dict[str, Any]):
        """ä¿å­˜è¯¦ç»†ä¿¡æ¯åˆ°detail.json"""
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path("models/nizima") / self.item_id
            output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜detail.json
            detail_file = output_dir / "detail.json"
            with open(detail_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ è¯¦ç»†ä¿¡æ¯å·²ä¿å­˜: {detail_file}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")

    def create_download_tasks(
        self, assets_info: AssetsInfo, temp_dir: Path
    ) -> List[DownloadTask]:
        """åˆ›å»ºä¸‹è½½ä»»åŠ¡åˆ—è¡¨"""
        tasks = []
        downloads_dir = temp_dir / "downloads"

        # 1. Preview Live2D ZIPæ–‡ä»¶
        if assets_info.preview_live2d_zip:
            file_name = assets_info.preview_live2d_zip["fileName"]
            url = f"{self.user_items_path}/{self.item_id}/{file_name}"

            task = DownloadTask(
                task_type=TaskType.PREVIEW_FILE,
                url=url,
                target_path=temp_dir / "preview" / file_name,
                temp_path=downloads_dir / file_name,
                needs_processing=True,
            )
            tasks.append(task)
            print(f"ğŸ“¦ Previewæ–‡ä»¶ä»»åŠ¡: {file_name}")
        else:
            print("âš ï¸ è¯¥ä½œå“æ²¡æœ‰Previewæ¨¡å‹æ–‡ä»¶")

        # 2. Export ZIPæ–‡ä»¶ï¼ˆå¦‚æœå¯ä¸‹è½½ï¼‰
        if assets_info.export_zip_info:
            item_content_id = assets_info.export_zip_info["itemContentId"]
            download_url = f"https://nizima.com/api/items/{item_content_id}/download"

            task = DownloadTask(
                task_type=TaskType.EXPORT_FILE,
                url=download_url,
                target_path=temp_dir / "export" / "export.zip",
                temp_path=downloads_dir / "export.zip",
                needs_processing=True,
                file_name="export.zip",
            )
            tasks.append(task)
            print(
                f"ğŸ“¦ Exportæ–‡ä»¶ä»»åŠ¡: export.zip (å¤§å°: {assets_info.export_zip_info.get('fileSize', 'Unknown')}MB)"
            )

        # 3. ç¼©ç•¥å›¾
        if assets_info.thumbnail_image:
            file_name = assets_info.thumbnail_image["fileName"]
            url = f"{self.user_items_path}/{self.item_id}/{file_name}"

            task = DownloadTask(
                task_type=TaskType.THUMBNAIL,
                url=url,
                target_path=temp_dir / "thumbnailImage" / file_name,
                temp_path=downloads_dir / f"thumb_{file_name}",
                needs_processing=False,
            )
            tasks.append(task)
            print(f"ğŸ–¼ï¸ ç¼©ç•¥å›¾ä»»åŠ¡: {file_name}")

        # 4. é¢„è§ˆå›¾ç‰‡
        if assets_info.preview_images:
            for i, img_info in enumerate(assets_info.preview_images):
                file_name = img_info["fileName"]
                url = f"{self.user_items_path}/{self.item_id}/images/{file_name}"

                task = DownloadTask(
                    task_type=TaskType.PREVIEW_IMAGE,
                    url=url,
                    target_path=temp_dir / "previewImages" / file_name,
                    temp_path=downloads_dir / f"preview_{i}_{file_name}",
                    needs_processing=False,
                )
                tasks.append(task)

            print(f"ğŸ–¼ï¸ é¢„è§ˆå›¾ä»»åŠ¡: {len(assets_info.preview_images)} å¼ ")

        print(f"ğŸ“‹ åˆ›å»ºäº† {len(tasks)} ä¸ªä¸‹è½½ä»»åŠ¡")
        return tasks


# ==================== ä¸»æ§åˆ¶å™¨ ====================


class NizimaFetcher:
    """Nizimaä¸‹è½½å™¨ä¸»æ§åˆ¶å™¨ v3.0"""

    def __init__(self, item_id: str, output_dir: str = "models/nizima"):
        self.item_id = str(item_id)
        self.output_dir = Path(output_dir)
        self.target_dir = self.output_dir / self.item_id
        self.model_name = None  # å­˜å‚¨æ¨¡å‹åç§°

    def _rename_target_dir_with_model_name(self, model_name: str) -> Path:
        """æ ¹æ®æ¨¡å‹åç§°é‡å‘½åç›®æ ‡ç›®å½•"""
        if not model_name or model_name == "unknown_model":
            return self.target_dir

        # åˆ›å»ºæ–°çš„ç›®å½•åï¼š{id}_{model_name}
        new_dir_name = f"{self.item_id}_{model_name}"
        new_target_dir = self.output_dir / new_dir_name

        # å¦‚æœå½“å‰ç›®å½•å­˜åœ¨ä¸”æ–°ç›®å½•åä¸åŒï¼Œåˆ™é‡å‘½å
        if self.target_dir.exists() and self.target_dir != new_target_dir:
            try:
                # å¦‚æœæ–°ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                if new_target_dir.exists():
                    shutil.rmtree(new_target_dir)

                # é‡å‘½åç›®å½•
                self.target_dir.rename(new_target_dir)
                print(
                    f"ğŸ“ ç›®å½•å·²é‡å‘½å: {self.target_dir.name} -> {new_target_dir.name}"
                )

                # æ›´æ–°target_dir
                self.target_dir = new_target_dir

            except Exception as e:
                print(f"âš ï¸ é‡å‘½åç›®å½•å¤±è´¥: {e}")

        return self.target_dir

    async def fetch(self) -> bool:
        """ä¸‹è½½ä½œå“"""
        print("ğŸš€ å¼€å§‹ä¸‹è½½ Nizima ä½œå“: {}".format(self.item_id))
        print("=" * 60)

        # æ£€æŸ¥ç‰ˆæœ¬ï¼Œå¦‚æœå·²æ˜¯æœ€æ–°ç‰ˆæœ¬åˆ™è·³è¿‡
        if check_version(self.item_id, self.output_dir):
            return True

        # å…ˆè·å–èµ„æºä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰previewæ¨¡å‹
        print("ğŸ“‹ è·å–èµ„æºä¿¡æ¯...")
        assets_manager = AssetsManager(self.item_id)
        assets_info, detail_data = await assets_manager.get_assets_info()

        # å¦‚æœæ²¡æœ‰previewæ¨¡å‹ï¼Œç›´æ¥è·³è¿‡ï¼Œä¸ä¿å­˜ä»»ä½•ä¿¡æ¯
        if not assets_info.preview_live2d_zip:
            print("âš ï¸ è¯¥ä½œå“æ²¡æœ‰Previewæ¨¡å‹ï¼Œç›´æ¥è·³è¿‡")
            return False

        try:
            # åˆ›å»ºSafeFileManagerå¹¶è®¾ç½®é‡å‘½åå›è°ƒ
            safe_manager = SafeFileManager(self.target_dir)
            safe_manager.set_rename_callback(
                lambda: (
                    self._rename_target_dir_with_model_name(self.model_name)
                    if self.model_name
                    else self.target_dir
                )
            )

            async with safe_manager.safe_operation() as ctx:
                # ä¿å­˜detail.jsonåˆ°ä¸´æ—¶ç›®å½•
                detail_path = ctx.temp_dir / "detail.json"
                detail_path.parent.mkdir(parents=True, exist_ok=True)
                with open(detail_path, "w", encoding="utf-8") as f:
                    json.dump(detail_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ detail.jsonå·²ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•: {detail_path}")

                # 2. åˆ›å»ºä¸‹è½½ä»»åŠ¡
                print("ğŸ“ åˆ›å»ºä¸‹è½½ä»»åŠ¡...")
                tasks = assets_manager.create_download_tasks(assets_info, ctx.temp_dir)

                if not tasks:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ä¸‹è½½çš„èµ„æº")
                    return False

                # 3. å¹¶å‘ä¸‹è½½
                print("â¬‡ï¸ å¼€å§‹å¹¶å‘ä¸‹è½½...")
                async with DownloadManager(max_concurrent=5) as download_manager:
                    results = await download_manager.download_tasks(tasks)

                    # è®°å½•å¤±è´¥çš„ä¸‹è½½
                    if download_manager.failed_downloads:
                        download_manager.write_failure_log(
                            self.output_dir, self.item_id
                        )

                # 4. å¤„ç†æ–‡ä»¶
                print("ğŸ”§ å¤„ç†ä¸‹è½½çš„æ–‡ä»¶...")
                success = await self._process_results(results, ctx.temp_dir)

                if success:
                    print("âœ… æ‰€æœ‰æ“ä½œå®Œæˆ")

                    # å¦‚æœæœ‰æ¨¡å‹åç§°ï¼Œæ›´æ–°ç‰ˆæœ¬ä¿¡æ¯ä¸­çš„æ¨¡å‹åç§°
                    model_name_for_version = (
                        self.model_name if self.model_name else "unknown"
                    )

                    # ä¿å­˜ç‰ˆæœ¬ä¿¡æ¯åˆ°ä¸´æ—¶ç›®å½•
                    version_file = ctx.temp_dir / "version.json"
                    version_data = {
                        "version": SCRIPT_VERSION,
                        "updated_at": datetime.now().isoformat(),
                        "item_id": self.item_id,
                        "model_name": model_name_for_version,
                    }
                    with open(version_file, "w", encoding="utf-8") as f:
                        json.dump(version_data, f, ensure_ascii=False, indent=2)
                    print(f"ğŸ’¾ ç‰ˆæœ¬ä¿¡æ¯å·²ä¿å­˜: {version_file} ({SCRIPT_VERSION})")
                    return True
                else:
                    print("âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
                    return False

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False

    async def _process_results(
        self, results: List[ProcessingResult], temp_dir: Path
    ) -> bool:
        """å¤„ç†ä¸‹è½½ç»“æœ"""
        success_count = 0
        total_count = len(results)

        for result in results:
            if not result.success:
                print(f"âš ï¸ è·³è¿‡å¤±è´¥çš„ä»»åŠ¡: {result.task.task_type.value}")
                continue

            try:
                if result.task.task_type == TaskType.PREVIEW_FILE:
                    model_name = await FileProcessor.process_main_file(
                        result.final_path, temp_dir, "preview"
                    )
                    if model_name:
                        result.model_name = model_name
                        print("âœ… Previewæ–‡ä»¶å¤„ç†å®Œæˆ")
                        success_count += 1

                elif result.task.task_type == TaskType.EXPORT_FILE:
                    success = await FileProcessor.process_main_file(
                        result.final_path, temp_dir, "export"
                    )
                    if success:
                        print("âœ… Exportæ–‡ä»¶å¤„ç†å®Œæˆ")
                        success_count += 1

                elif result.task.task_type == TaskType.THUMBNAIL:
                    target_dir = temp_dir / "thumbnailImage"
                    success = await FileProcessor.process_image(
                        result.final_path, target_dir
                    )
                    if success:
                        print(f"âœ… å›¾ç‰‡å¤„ç†å®Œæˆ: {result.final_path.name}")
                        success_count += 1

                elif result.task.task_type == TaskType.PREVIEW_IMAGE:
                    target_dir = temp_dir / "previewImages"
                    success = await FileProcessor.process_image(
                        result.final_path, target_dir
                    )
                    if success:
                        print(f"âœ… å›¾ç‰‡å¤„ç†å®Œæˆ: {result.final_path.name}")
                        success_count += 1

            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {result.final_path}: {e}")

        print(f"ğŸ“Š å¤„ç†ç»“æœ: {success_count}/{total_count} æˆåŠŸ")

        # æå–æ¨¡å‹åç§°å¹¶é‡å‘½åç›®å½•
        model_name = None
        for result in results:
            if result.success and result.model_name:
                model_name = result.model_name
                break

        if model_name:
            self.model_name = model_name
            print(f"ğŸ­ æå–åˆ°æ¨¡å‹åç§°: {model_name}")

        return success_count > 0


# ==================== æ‰¹é‡ä¸‹è½½ ====================


async def fetch_multiple_items(
    item_ids: List[str], output_dir: str = "models/nizima", max_concurrent: int = 3
) -> None:
    """æ‰¹é‡ä¸‹è½½å¤šä¸ªä½œå“"""
    print(f"ğŸš€ å¼€å§‹å¹¶å‘ä¸‹è½½ {len(item_ids)} ä¸ªä½œå“")
    print(f"ğŸ“‹ ä½œå“åˆ—è¡¨: {', '.join(item_ids)}")
    print(f"ğŸ”§ æœ€å¤§å¹¶å‘æ•°: {max_concurrent}")
    print("=" * 80)

    # åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(max_concurrent)

    async def download_single(item_id: str) -> bool:
        """ä¸‹è½½å•ä¸ªä½œå“"""
        async with semaphore:
            # æ£€æŸ¥æ˜¯å¦è¯·æ±‚å…³é—­
            if is_shutdown_requested():
                print(f"ğŸ›‘ è·³è¿‡ä½œå“ {item_id}ï¼ˆç”¨æˆ·è¯·æ±‚ä¸­æ–­ï¼‰")
                return False

            print(f"\nğŸ¯ å¼€å§‹å¤„ç†ä½œå“: {item_id}")
            try:
                fetcher = NizimaFetcher(item_id, output_dir)
                success = await fetcher.fetch()
                if success:
                    print(f"âœ… ä½œå“ {item_id} ä¸‹è½½æˆåŠŸ")
                    return True
                else:
                    print(f"âŒ ä½œå“ {item_id} ä¸‹è½½å¤±è´¥")
                    return False
            except KeyboardInterrupt:
                print(f"ğŸ›‘ ä½œå“ {item_id} è¢«ç”¨æˆ·ä¸­æ–­")
                return False
            except Exception as e:
                print(f"âŒ ä½œå“ {item_id} ä¸‹è½½å¼‚å¸¸: {e}")
                return False

    # æ‰§è¡Œå¹¶å‘ä¸‹è½½
    results = await asyncio.gather(
        *[download_single(item_id) for item_id in item_ids], return_exceptions=True
    )

    # ç»Ÿè®¡ç»“æœ
    successful = 0
    failed_items = []

    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"âŒ ä½œå“ {item_ids[i]} å‘ç”Ÿå¼‚å¸¸: {result}")
            failed_items.append(item_ids[i])
        elif result:
            successful += 1
        else:
            failed_items.append(item_ids[i])

    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š æ‰¹é‡ä¸‹è½½å®Œæˆ")
    print("=" * 80)
    print(f"âœ… æˆåŠŸ: {successful}/{len(item_ids)} ä¸ªä½œå“")

    if failed_items:
        print(f"âŒ å¤±è´¥: {len(failed_items)} ä¸ªä½œå“")
        print(f"å¤±è´¥åˆ—è¡¨: {', '.join(failed_items)}")
    else:
        print("ğŸ‰ æ‰€æœ‰ä½œå“ä¸‹è½½å®Œæˆ!")


# ==================== å‘½ä»¤è¡Œæ¥å£ ====================


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    parser = argparse.ArgumentParser(description="Nizima Live2Dæ¨¡å‹ä¸‹è½½å™¨ v3.0")
    parser.add_argument("item_ids", nargs="+", help="ä½œå“IDåˆ—è¡¨")
    parser.add_argument("--output", "-o", default="models/nizima", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--concurrent", "-c", type=int, default=3, help="æœ€å¤§å¹¶å‘æ•°")

    args = parser.parse_args()

    try:
        if len(args.item_ids) == 1:
            # å•ä¸ªä½œå“ä¸‹è½½
            fetcher = NizimaFetcher(args.item_ids[0], args.output)
            success = await fetcher.fetch()

            if is_shutdown_requested():
                print("\nğŸ›‘ ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
            elif success:
                print(
                    f"\nğŸ‰ ä¸‹è½½å®Œæˆ! æ–‡ä»¶ä¿å­˜åœ¨: {Path(args.output) / args.item_ids[0]}"
                )
            else:
                print("\nâŒ ä¸‹è½½å¤±è´¥")
        else:
            # æ‰¹é‡ä¸‹è½½
            await fetch_multiple_items(
                list(set(args.item_ids)), args.output, args.concurrent
            )

            if is_shutdown_requested():
                print("\nğŸ›‘ æ‰¹é‡ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
                print("ğŸ’¡ æç¤ºï¼šå·²å®Œæˆçš„ä¸‹è½½ä¼šè¢«ä¿ç•™ï¼Œæœªå®Œæˆçš„å¯ä»¥é‡æ–°è¿è¡Œ")

    except KeyboardInterrupt:
        print("\nğŸ›‘ ä¸‹è½½è¢«ç”¨æˆ·ä¸­æ–­")
        print("ğŸ’¡ æç¤ºï¼šç³»ç»Ÿå·²å®‰å…¨æ¸…ç†ï¼Œå¯ä»¥é‡æ–°è¿è¡Œ")


if __name__ == "__main__":
    asyncio.run(main())
